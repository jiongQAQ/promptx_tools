#!/usr/bin/env python3
"""
Claude Code UserPromptSubmit Hook for 05 Chapter Content Generation
This hook automatically injects context for batch processing chapter content generation.
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime

def main():
    try:
        # è¯»å–ç”¨æˆ·è¾“å…¥
        input_data = json.loads(sys.stdin.read())
        user_prompt = input_data.get('prompt', '')

        # æ£€æŸ¥è§¦å‘æ–‡ä»¶æˆ–05æµç¨‹æŒ‡ä»¤
        project_root = os.getcwd()
        trigger_file = Path(project_root) / 'paper' / '.auto-trigger'

        is_05_command = '05æµç¨‹' in user_prompt or 'æ­£æ–‡ç”Ÿæˆ' in user_prompt
        has_trigger_file = trigger_file.exists()

        if is_05_command or has_trigger_file:
            # åˆ é™¤è§¦å‘æ–‡ä»¶
            if has_trigger_file:
                trigger_file.unlink()

            # å¦‚æœæ˜¯é€šè¿‡è§¦å‘æ–‡ä»¶è§¦å‘çš„ï¼Œä¿®æ”¹ç”¨æˆ·æç¤º
            if has_trigger_file and not is_05_command:
                user_prompt = "å¼€å§‹05æµç¨‹"

            progress_file = Path(project_root) / 'paper' / '.chapter-progress.json'

            # è¯»å–æˆ–åˆå§‹åŒ–è¿›åº¦çŠ¶æ€
            progress = load_progress(progress_file)

            if not progress['initialized']:
                # åˆå§‹åŒ–ï¼šæ‰«æç« èŠ‚æ–‡ä»¶
                chapters = scan_chapter_files(Path(project_root) / 'paper' / 'chapters')
                if not chapters:
                    context = "âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°chapterç›®å½•æˆ–ç« èŠ‚æ–‡ä»¶ã€‚è¯·ç¡®ä¿å·²æ‰§è¡Œ04ç« èŠ‚åˆ‡å‰²æµç¨‹ã€‚"
                else:
                    progress = initialize_progress(chapters, progress_file)
                    context = generate_single_chapter_context(progress, project_root)
            else:
                # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆ
                if not progress['pending']:
                    context = "ğŸ‰ 05æµç¨‹å·²å®Œæˆï¼æ‰€æœ‰ç« èŠ‚å†…å®¹ç”Ÿæˆå®Œæ¯•ã€‚"
                else:
                    # è‡ªåŠ¨æ›´æ–°è¿›åº¦ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ç« èŠ‚å·²å®Œæˆ
                    updated_progress = update_progress_from_files(progress, project_root)
                    if updated_progress != progress:
                        progress_file.write_text(json.dumps(updated_progress, indent=2, ensure_ascii=False), encoding='utf-8')
                        progress = updated_progress

                    context = generate_single_chapter_context(progress, project_root)

            # è¿”å›å¢å¼ºçš„ä¸Šä¸‹æ–‡
            output = {
                "hookSpecificOutput": {
                    "hookEventName": "UserPromptSubmit",
                    "additionalContext": context
                }
            }
            print(json.dumps(output))

        # å…¶ä»–æƒ…å†µä¸åšå¤„ç†ï¼Œè®©æç¤ºæ­£å¸¸æ‰§è¡Œ

    except Exception as e:
        # é”™è¯¯å¤„ç†ï¼šè¾“å‡ºé”™è¯¯ä¿¡æ¯ä½†ä¸é˜»å¡æ­£å¸¸æµç¨‹
        error_output = {
            "hookSpecificOutput": {
                "hookEventName": "UserPromptSubmit",
                "additionalContext": f"âš ï¸ Hookå¤„ç†é”™è¯¯: {str(e)}"
            }
        }
        print(json.dumps(error_output))

def load_progress(progress_file):
    """åŠ è½½æˆ–åˆ›å»ºè¿›åº¦çŠ¶æ€"""
    if progress_file.exists():
        try:
            return json.loads(progress_file.read_text(encoding='utf-8'))
        except:
            pass

    return {
        "initialized": False,
        "currentBatch": 1,
        "batchSize": 4,
        "processed": [],
        "pending": [],
        "failed": [],
        "lastUpdate": datetime.now().isoformat()
    }

def scan_chapter_files(chapter_dir):
    """æ‰«æå¹¶æ’åºç« èŠ‚æ–‡ä»¶"""
    if not chapter_dir.exists():
        return []

    chapters = []
    for file in chapter_dir.glob('chapter.*.json'):
        chapter_id = file.stem.replace('chapter.', '')
        chapters.append(chapter_id)

    # æŒ‰ç« èŠ‚ç¼–å·æ’åº
    return sorted(chapters, key=lambda x: parse_chapter_id(x))

def parse_chapter_id(chapter_id):
    """è§£æç« èŠ‚IDç”¨äºæ’åº"""
    parts = []
    for part in chapter_id.split('.'):
        try:
            parts.append(int(part))
        except ValueError:
            parts.append(part)
    return parts

def initialize_progress(chapters, progress_file):
    """åˆå§‹åŒ–è¿›åº¦çŠ¶æ€"""
    progress = {
        "initialized": True,
        "currentBatch": 1,
        "batchSize": 4,
        "totalChapters": len(chapters),
        "processed": [],
        "pending": chapters.copy(),
        "failed": [],
        "totalBatches": (len(chapters) + 3) // 4,  # å‘ä¸Šå–æ•´
        "lastUpdate": datetime.now().isoformat()
    }

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    progress_file.parent.mkdir(parents=True, exist_ok=True)
    progress_file.write_text(json.dumps(progress, indent=2, ensure_ascii=False), encoding='utf-8')
    return progress

def generate_single_chapter_context(progress, project_root):
    """ç”Ÿæˆå•ä¸ªç« èŠ‚çš„å¤„ç†ä¸Šä¸‹æ–‡"""
    remaining_chapters = progress['pending']

    if not remaining_chapters:
        return "ğŸ‰ æ‰€æœ‰ç« èŠ‚å·²å¤„ç†å®Œæˆï¼"

    # åªå–ç¬¬ä¸€ä¸ªå¾…å¤„ç†ç« èŠ‚
    current_chapter = remaining_chapters[0]

    total_chapters = progress['totalChapters']
    processed_count = len(progress['processed'])

    context = f"ğŸ“ å¤„ç†å•ä¸ªç« èŠ‚ï¼š{current_chapter}\n\n"

    # è·å–ç« èŠ‚è¯¦ç»†ä¿¡æ¯
    chapter_file = Path(project_root) / 'paper' / 'chapters' / f'chapter.{current_chapter}.json'

    if chapter_file.exists():
        try:
            chapter_data = json.loads(chapter_file.read_text(encoding='utf-8'))
            title = chapter_data.get('title', f'ç« èŠ‚{current_chapter}')
            prompt = chapter_data.get('prompt', 'ç”Ÿæˆæ­£æ–‡å†…å®¹')
            word_limit = chapter_data.get('word_limit', determine_word_limit(current_chapter))

            context += f"ğŸ“– ç« èŠ‚ä¿¡æ¯ï¼š\n"
            context += f"- ID: {current_chapter}\n"
            context += f"- æ ‡é¢˜: {title}\n"
            context += f"- å­—æ•°è¦æ±‚: {word_limit}å­—\n"
            context += f"- ç”Ÿæˆè¦æ±‚: {prompt}\n\n"

        except Exception as e:
            context += f"âŒ è¯»å–ç« èŠ‚æ–‡ä»¶å¤±è´¥: {str(e)}\n\n"
    else:
        context += f"âŒ ç« èŠ‚æ–‡ä»¶ä¸å­˜åœ¨: {chapter_file}\n\n"

    # è¿›åº¦ä¿¡æ¯
    percentage = (processed_count / total_chapters * 100) if total_chapters > 0 else 0
    context += f"ğŸ“ˆ å½“å‰è¿›åº¦: {processed_count}/{total_chapters} ({percentage:.1f}%)\n\n"

    # æ·»åŠ å·¥ä½œæµç¨‹æ–‡æ¡£å¼•ç”¨
    context += "ğŸ“– **å‚è€ƒæ–‡æ¡£**: workflows/05 æ­£æ–‡å†…å®¹ç”Ÿæˆ.md\n"
    context += "è¯·æŒ‰ç…§è¯¥æ–‡æ¡£ä¸­çš„å†…å®¹ç”ŸæˆåŸåˆ™ã€ç‰¹æ®Šå¤„ç†è§„åˆ™å’Œè´¨é‡æ ‡å‡†æ‰§è¡Œã€‚\n\n"

    context += "ğŸ¯ å½“å‰ä»»åŠ¡ï¼š\n"
    context += f"è¯·ä¸“æ³¨å¤„ç†ç« èŠ‚ {current_chapter}ï¼Œä¸ºå…¶ç”Ÿæˆtextå­—æ®µå†…å®¹ã€‚\n\n"

    context += "æ“ä½œè¦æ±‚ï¼š\n"
    context += "1. æ¿€æ´»promptxçš„praè§’è‰²è¿›è¡Œä¸“ä¸šè®ºæ–‡å†™ä½œ\n"
    context += "2. ä¸¥æ ¼æŒ‰ç…§ç« èŠ‚çš„promptè¦æ±‚ç”Ÿæˆå†…å®¹\n"
    context += "3. æ§åˆ¶å­—æ•°åœ¨æŒ‡å®šèŒƒå›´å†…ï¼ˆå…è®¸Â±10%æµ®åŠ¨ï¼‰\n"
    context += "4. é¿å…ä»£ç ç‰‡æ®µå’Œæ–‡ä»¶è·¯å¾„æè¿°\n"
    context += "5. ä½¿ç”¨Editå·¥å…·æ›´æ–°å¯¹åº”çš„JSONæ–‡ä»¶\n"
    context += "6. ä»…æ›´æ–°textå­—æ®µï¼Œä¿æŒå…¶ä»–å­—æ®µä¸å˜\n"
    context += "7. å®Œæˆåç®€å•æŠ¥å‘Šè¯¥ç« èŠ‚å·²å®Œæˆ\n\n"

    context += "âš ï¸ é‡è¦ï¼šåªå¤„ç†è¿™ä¸€ä¸ªç« èŠ‚ï¼Œå®ŒæˆåStop Hookä¼šè‡ªåŠ¨è§¦å‘ä¸‹ä¸€ç« èŠ‚ï¼\n"

    return context


def determine_word_limit(chapter_id):
    """æ ¹æ®ç« èŠ‚å±‚çº§è‡ªåŠ¨ç¡®å®šå­—æ•°"""
    levels = chapter_id.count('.')
    if levels == 0:  # ä¸€çº§ç« èŠ‚
        return 800
    elif levels == 1:  # äºŒçº§ç« èŠ‚
        return 600
    elif levels == 2:  # ä¸‰çº§ç« èŠ‚
        return 500
    else:  # å››çº§åŠä»¥ä¸‹
        return 400

def update_progress_after_completion(progress, progress_file, completed_chapters):
    """æ›´æ–°å¤„ç†å®Œæˆåçš„è¿›åº¦"""
    progress['processed'].extend(completed_chapters)
    progress['pending'] = [ch for ch in progress['pending'] if ch not in completed_chapters]
    progress['currentBatch'] += 1
    progress['lastUpdate'] = datetime.now().isoformat()

    progress_file.write_text(json.dumps(progress, indent=2, ensure_ascii=False), encoding='utf-8')

if __name__ == "__main__":
    main()